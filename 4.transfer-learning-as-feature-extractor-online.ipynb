{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tqdm\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport random\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom shutil import copyfile\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelif(torch.backends.mps.is_available()):\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CAT_DIR = '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat'\nDOG_DIR = '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    os.mkdir('/kaggle/working/tmp')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/training')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/validation')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/training/cats')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/training/dogs')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/validation/cats')\n    os.mkdir('/kaggle/working/tmp/cats-v-dogs/validation/dogs')\nexcept OSError:\n    print('Error failed to make directory')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_data(main_dir, training_dir, validation_dir, split_size):\n    \"\"\"\n    Splits the data into train and test sets\n\n    Args:\n    main_dir (string):  path containing the images\n    training_dir (string):  path to be used for training\n    validation_dir (string):  path to be used for validation\n    split_size (float): size of the dataset to be used for training\n    \"\"\"\n    files = []\n    for file in os.listdir(main_dir):\n        if  os.path.getsize(os.path.join(main_dir, file)): # check if the file's size isn't 0\n            files.append(file) # appends file name to a list\n\n    shuffled_files = random.sample(files,  len(files)) # shuffles the data\n    split = int(0.9 * len(shuffled_files)) #the training split casted into int for numeric rounding\n    train = shuffled_files[:split] #training split\n    validation = shuffled_files[split:] # validation split\n\n    for element in train:\n        copyfile(os.path.join(main_dir,  element), os.path.join(training_dir, element)) # copy files into training directory\n\n    for element in validation:\n        copyfile(os.path.join(main_dir,  element), os.path.join(validation_dir, element))# copy files into validation directory\n        \nsplit_data(CAT_DIR, '/kaggle/working/tmp/cats-v-dogs/training/cats','/kaggle/working/tmp/cats-v-dogs/validation/cats', 0.9)\nsplit_data(DOG_DIR, '/kaggle/working/tmp/cats-v-dogs/training/dogs', '/kaggle/working/tmp/cats-v-dogs/validation/dogs', 0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\nvalid_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder('/kaggle/working/tmp/cats-v-dogs/training' , transform=train_transform)\nvalid_dataset = datasets.ImageFolder('/kaggle/working/tmp/cats-v-dogs/validation',transform=valid_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unnormalize(img):\n        # unnormalize\n    img[0]= img[0]*std[0] + mean[0]\n    img[1]= img[1]*std[1] + mean[1]\n    img[2]= img[2]*std[2] + mean[2]\n    return img\n    \ndef imshow(img):\n    # unnormalize\n    img = unnormalize(img)\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For train_loader\ntrain_batch = next(iter(train_loader))\nimages_train, labels_train = train_batch\n\n# For val_loader\nval_batch = next(iter(val_loader))\nimages_val, labels_val = val_batch\n# For train_loader\nrandom_index_train = np.random.randint(images_train.size(0))\nrandom_image_train = images_train[random_index_train]\nrandom_label_train = labels_train[random_index_train]\n\n# For val_loader\nrandom_index_val = np.random.randint(images_val.size(0))\nrandom_image_val = images_val[random_index_val]\nrandom_label_val = labels_val[random_index_val]\n# For train_loader\nrandom_image_train_np = random_image_train.numpy()\nplt.imshow(np.transpose(random_image_train_np, (1, 2, 0)))\nplt.title(f\"Label: {random_label_train.item()}\")\nplt.axis('off')\nplt.show()\n\n# For val_loader\nrandom_image_val_np = random_image_val.numpy()\nplt.imshow(np.transpose(random_image_val_np, (1, 2, 0)))\nplt.title(f\"Label: {random_label_val.item()}\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_iter = iter(train_loader)\nfirst_batch = next(data_iter)\n\nprint(\"Training Batch Size = \" ,first_batch[0].shape , \"| Val Batch Size\" , first_batch[1].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Features Using Transfer Learning","metadata":{}},{"cell_type":"code","source":"conv_base = torchvision.models.vgg16(pretrained = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Extraction Part \nconv_base.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classifier Part In Pretrained Model\nconv_base.classifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(conv_base, images ):\n    \n    conv_base.eval()\n    with torch.no_grad():\n        features = conv_base.features(images)\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing Classifier Part with Trainable Parameters","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        \n        super().__init__()\n        self.fc1 = nn.Linear(25088, 512)  \n        self.fc2 = nn.Linear(512, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = torch.flatten(x,1)\n        \n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        x = x.reshape(-1)\n        \n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net()\nmodel.to(device)\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n# Training loop\ntrain_acc = []\ntrain_loss = []\nval_acc = []\nval_loss = []\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    model.train()  # Set the model to training mode\n\n    for images, labels in train_loader:\n        \n        images = conv_base.features(images)\n        images = images.to(device)  # Move the input tensor to the GPU\n        labels = labels.to(device)  # Move the labels tensor to the GPU\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n        labels = labels.to(torch.float32)\n\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Calculate training accuracy\n        predicted = torch.round(outputs)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    training_loss = running_loss / len(train_loader)\n    training_accuracy = 100 * correct_train / total_train\n\n    # Evaluation on test set\n    model.eval()  # Set the model to evaluation mode\n    test_loss = 0.0\n    correct_test = 0\n    total_test = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)  # Move the input tensor to the GPU\n            labels = labels.to(device)  # Move the labels tensor to the GPU\n\n            outputs = model(images)\n            labels = labels.to(torch.float32)\n\n            # Adjust the shape of labels to match the output shape\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n\n            # Calculate test accuracy\n            predicted = torch.round(outputs)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_loss /= len(val_loader)\n    test_accuracy = 100 * correct_test / total_test\n\n    train_acc.append(training_accuracy)\n    train_loss.append(training_loss)\n    val_acc.append(test_accuracy)\n    val_loss.append(test_loss)\n\n    # Print the average loss and accuracy for this epoch\n    print(f\"Epoch {epoch+1}:\")\n    print(f\"  Train Loss: {training_loss:.4f} | Train Accuracy: {training_accuracy:.2f}%\")\n    print(f\"  Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n    print(\"*************************\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_state = model.state_dict()\n# torch.save(final_state, 'model_state.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n# t = f.suptitle(' Vanilla CNN Performance', fontsize=12)\n# f.subplots_adjust(top=0.85, wspace=0.3)\n\n# epoch_list = list(range(1,num_epochs+1))\n# ax1.plot(epoch_list, train_acc, label='Train Accuracy')\n# ax1.plot(epoch_list, val_acc, label='Validation Accuracy')\n# ax1.set_xticks(np.arange(0, 60, 5))\n# ax1.set_ylabel('Accuracy Value')\n# ax1.set_xlabel('Epoch')\n# ax1.set_title('Accuracy')\n# l1 = ax1.legend(loc=\"best\")\n\n# ax2.plot(epoch_list, train_loss, label='Train Loss')\n# ax2.plot(epoch_list, val_loss, label='Validation Loss')\n# ax2.set_xticks(np.arange(0, 60, 5))\n# ax2.set_ylabel('Loss Value')\n# ax2.set_xlabel('Epoch')\n# ax2.set_title('Loss')\n# l2 = ax2.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}